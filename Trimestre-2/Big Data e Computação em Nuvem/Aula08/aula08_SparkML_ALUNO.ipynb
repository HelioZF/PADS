{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSKFI6-04INV"
   },
   "source": [
    "Insper\n",
    "\n",
    "# Aula 08 - Spark ML - Machine Learning com Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CneaKy24INh"
   },
   "source": [
    "Vamos fazer o setup de nosso ambiente Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T14:00:57.733045Z",
     "start_time": "2021-06-12T14:00:53.405830Z"
    },
    "id": "t4HJrYLU4INk"
   },
   "outputs": [],
   "source": [
    "# Criar a sessao do Spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .appName(\"MUDE_AQUI\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLOeooON4INq"
   },
   "source": [
    "## Modelo de regressão linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T20:58:53.538860Z",
     "start_time": "2021-06-06T20:58:53.534811Z"
    },
    "id": "jWucTAoO4INs"
   },
   "source": [
    "Vamos usar o clássico conjunto de dados de Advertising para predizer o número de vendas de um produto, em função dos valores gastos em campanhas de TV, Radio e Jornal.\n",
    "\n",
    "Iniciamos com a leitura do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T14:01:24.934600Z",
     "start_time": "2021-06-12T14:01:21.706726Z"
    },
    "id": "lGWHhXbc4INu"
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv('Advertising.csv',\n",
    "                      header=True,\n",
    "                      inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwtLrWgg4INw"
   },
   "source": [
    "Exiba as primeiras cinco linhas do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rMDOmj2L4INy"
   },
   "outputs": [],
   "source": [
    "data = data.drop(\"_c0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNeqPk6O4INz"
   },
   "source": [
    "Remova a coluna `_c0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T20:59:46.819901Z",
     "start_time": "2021-06-06T20:59:46.815606Z"
    },
    "id": "zoZDbkvy4IN1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|               TV|             Radio|         Newspaper|             Sales|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|              200|               200|               200|               200|\n",
      "|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n",
      "| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n",
      "|    min|              0.7|               0.0|               0.3|               1.6|\n",
      "|    max|            296.4|              49.6|             114.0|              27.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YECHku2D4IN2"
   },
   "source": [
    "Exiba novamente as primeiras cinco linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T19:58:24.522759Z",
     "start_time": "2021-06-06T19:58:24.415440Z"
    },
    "id": "CG-1vV_B4IN7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxRMTE6I4IN8"
   },
   "source": [
    "Vamos agora exibir as principais estatísticas descritivas do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:00:12.710586Z",
     "start_time": "2021-06-06T21:00:12.599020Z"
    },
    "id": "DmzopxpW4IN-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-YOF1n_4IN_"
   },
   "source": [
    "O Spark faz uso de uma interface similar ao Scikit-Learn para desenvolver modelos preditivos. Baseado no conceito de `transformer`, nós vamos transformando o dataset em outro dataset com os ajustes necessários para o desenvolvimento de nosso modelo.\n",
    "\n",
    "A estrutura de dados mais utilizada para o desenvolvimento de modelos é o `Vector` que possui, dentre outras funções, um bom suporte para dados esparsos.\n",
    "\n",
    "Agora vamos importar o `VectorAssembler` que está em `pyspark.ml.feature` e também o modelo de regrssão linear (`LinearRegression`) que está em `pyspark.ml.regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:02:23.886739Z",
     "start_time": "2021-06-06T21:02:23.884059Z"
    },
    "id": "B8BpyFm34IOB"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8-NlRaw4IOD"
   },
   "source": [
    "Vamos dividir os dados no conjunto de treino (70%) e teste (30%), como segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:02:53.924665Z",
     "start_time": "2021-06-06T21:02:53.916321Z"
    },
    "id": "tjx-mt6F4IOG"
   },
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7,0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1OIuvG94IOI"
   },
   "source": [
    "Para desenvolver seu modelo em Spark, você precisará ter uma coluna denominada `features`, que será resultado de todos os processos de transformação de dados necessários para o correto desenvolvimento dos modelos.\n",
    "\n",
    "Vamos criar uma variável chamada `vec` que será o nosso `VectorAssembler`. Devemos informar quais colunas serão concatenadas em um `vector` e qual será o nome desse `vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:04:32.813138Z",
     "start_time": "2021-06-06T21:04:32.806651Z"
    },
    "id": "uXuv4OjF4IOL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TV', 'Radio', 'Newspaper']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[:-1] # tudo meno o ultimo valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VVNrcZu4IOM"
   },
   "source": [
    "Feito isso, podemos ver o resultado usando a função `transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:04:55.049155Z",
     "start_time": "2021-06-06T21:04:55.036691Z"
    },
    "id": "9VfZ_sSp4IOO"
   },
   "outputs": [],
   "source": [
    "vec = VectorAssembler(inputCols=data.columns[:-1],outputCol=\"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:04:55.567368Z",
     "start_time": "2021-06-06T21:04:55.555647Z"
    },
    "id": "Tb-rkULi4IOP"
   },
   "outputs": [],
   "source": [
    "train = vec.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vec.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hSfeZBN4IOQ"
   },
   "source": [
    "Exiba as cinco primeiras linhas de train e, posteriormente, de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:05:09.977364Z",
     "start_time": "2021-06-06T21:05:09.916458Z"
    },
    "id": "zRqvUiTA4IOR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+-----+---------------+\n",
      "| TV|Radio|Newspaper|Sales|       Features|\n",
      "+---+-----+---------+-----+---------------+\n",
      "|0.7| 39.6|      8.7|  1.6| [0.7,39.6,8.7]|\n",
      "|4.1| 11.6|      5.7|  3.2| [4.1,11.6,5.7]|\n",
      "|7.3| 28.1|     41.4|  5.5|[7.3,28.1,41.4]|\n",
      "|7.8| 38.9|     50.6|  6.6|[7.8,38.9,50.6]|\n",
      "|8.4| 27.2|      2.1|  5.7| [8.4,27.2,2.1]|\n",
      "+---+-----+---------+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:05:13.369631Z",
     "start_time": "2021-06-06T21:05:13.285646Z"
    },
    "id": "TAu-WtBn4IOS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+-----+----------------+\n",
      "|  TV|Radio|Newspaper|Sales|        Features|\n",
      "+----+-----+---------+-----+----------------+\n",
      "| 5.4| 29.9|      9.4|  5.3|  [5.4,29.9,9.4]|\n",
      "| 8.6|  2.1|      1.0|  4.8|   [8.6,2.1,1.0]|\n",
      "|11.7| 36.9|     45.2|  7.3|[11.7,36.9,45.2]|\n",
      "|13.1|  0.4|     25.6|  5.3| [13.1,0.4,25.6]|\n",
      "|17.2| 45.9|     69.3|  9.3|[17.2,45.9,69.3]|\n",
      "+----+-----+---------+-----+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4Vi9y9i4IOT"
   },
   "source": [
    "É possível observar a coluna `features`. Veja o schema do dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:05:42.637559Z",
     "start_time": "2021-06-06T21:05:42.634152Z"
    },
    "id": "h666NTj84IOU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TV: double (nullable = true)\n",
      " |-- Radio: double (nullable = true)\n",
      " |-- Newspaper: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      " |-- Features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXVlGvNN4IOX"
   },
   "source": [
    "Agora chegou a vez de criarmos o nosso modelo de regressão linear. Você precisa informar dois parâmetros: `featureCol` (qual é a coluna que possui um vector das features) e `labelCol` que representa a coluna que possui a variável dependente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:06:53.449182Z",
     "start_time": "2021-06-06T21:06:53.442629Z"
    },
    "id": "cwU8fpfk4IOZ"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = \"Features\", labelCol =\"Sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO_ywFQ34IOa"
   },
   "source": [
    "Análogo ao `scikit-learn`, use o método `fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:07:08.607106Z",
     "start_time": "2021-06-06T21:07:08.332507Z"
    },
    "id": "1SJbo1Q84IOb"
   },
   "outputs": [],
   "source": [
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86Z8dPBp4IOc"
   },
   "source": [
    "O atributo `coefficients` e o atributo `intercept` apresentam, respectivamente, os coeficientes da regressão linear e o valor do intercepto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:07:40.158179Z",
     "start_time": "2021-06-06T21:07:40.150251Z"
    },
    "id": "CKj4VB_M4IOc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0459, 0.2009, -0.0035])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:07:40.735264Z",
     "start_time": "2021-06-06T21:07:40.731560Z"
    },
    "id": "_qU7Wu-h4IOd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.735554921884289"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14KSzhYl4IOe"
   },
   "source": [
    "E podemos usar a função `evaluate` para criar uma variável que nos permitirá obter as métricas comuns de desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:08:12.730164Z",
     "start_time": "2021-06-06T21:08:12.570176Z"
    },
    "id": "BJtjTEvk4IOg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAR :  1.3365541938281162\n",
      "RMSE :  1.6614200921535163\n",
      "R2 :  0.8651044648239229\n"
     ]
    }
   ],
   "source": [
    "evaluation_summary = lrModel.evaluate(test)\n",
    "\n",
    "print(\"MAR : \", evaluation_summary.meanAbsoluteError)\n",
    "print(\"RMSE : \", evaluation_summary.rootMeanSquaredError)\n",
    "print(\"R2 : \", evaluation_summary.r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x04uUcrX4IOh"
   },
   "source": [
    "# Profissionalizando nossos modelos com Pipeline\n",
    "\n",
    "\n",
    "De fato, há inúmeros procedimentos que fazemos com os dados antes de treinar um modelo. Há processos de limpeza, padronização, one hot encoding, etc.\n",
    "\n",
    "Veja nesse link [https://spark.apache.org/docs/latest/ml-features](https://spark.apache.org/docs/latest/ml-features) as mais diversa funções que podemos fazer nos dados com o Spark. Há códigos de exemplo para lhe auxiliar no aprendizado.\n",
    "\n",
    "Vamos comecar importando `Pipeline` que está em `pyspark.ml`. E com isso vamos definir um pipeline formado por 2 estágios: vec (transforma as features em vector) e lr (nosso modelo de regressão linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:10:58.948679Z",
     "start_time": "2021-06-06T21:10:58.945344Z"
    },
    "id": "u5yEwCCB4IOi"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLN8N7Cc4IOk"
   },
   "source": [
    "E agora criamos nosso pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:12:22.017627Z",
     "start_time": "2021-06-06T21:12:22.014597Z"
    },
    "editable": true,
    "id": "wWhl_ent4IOl",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[vec,lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0z-VpBC4IOl"
   },
   "source": [
    "Vamos dividir novamente os dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7,0.3],seed=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:12:16.828533Z",
     "start_time": "2021-06-06T21:12:16.821730Z"
    },
    "id": "b0SHWgIK4IOm"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRX7J0F14IOn"
   },
   "source": [
    "Agora podemos usar a função `fit()` do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:12:24.453478Z",
     "start_time": "2021-06-06T21:12:24.119619Z"
    },
    "id": "SNznS5i_4IOp"
   },
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dk9-Q-1R4IOq"
   },
   "source": [
    "Execute a função `transform` sob o conjunto de teste (`test`) e salve em `pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:12:48.547816Z",
     "start_time": "2021-06-06T21:12:48.521442Z"
    },
    "id": "Mw7bitk54IOr"
   },
   "outputs": [],
   "source": [
    "pred = pipelineModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:12:48.970008Z",
     "start_time": "2021-06-06T21:12:48.900066Z"
    },
    "id": "oC-92f-s4IOr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+-----+----------------+------------------+\n",
      "|  TV|Radio|Newspaper|Sales|        Features|        prediction|\n",
      "+----+-----+---------+-----+----------------+------------------+\n",
      "| 5.4| 29.9|      9.4|  5.3|  [5.4,29.9,9.4]| 8.958660646510964|\n",
      "| 8.6|  2.1|      1.0|  4.8|   [8.6,2.1,1.0]| 3.548735670229508|\n",
      "|11.7| 36.9|     45.2|  7.3|[11.7,36.9,45.2]| 10.52918016473767|\n",
      "|13.1|  0.4|     25.6|  5.3| [13.1,0.4,25.6]|3.3276257934037154|\n",
      "|17.2| 45.9|     69.3|  9.3|[17.2,45.9,69.3]|12.505787163829279|\n",
      "+----+-----+---------+-----+----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mA92C7mX4IOs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY37mQdw4IOt"
   },
   "source": [
    "## Melhorando nosso pipeline com feature engineering\n",
    "\n",
    "Lembre-se desse link para ver as mais usadas transformações nos dados: [https://spark.apache.org/docs/latest/ml-features](https://spark.apache.org/docs/latest/ml-features)\n",
    "\n",
    "\n",
    "Vamos desenvolver outro modelo preditivo. Agora para predizer o gasto em planos de saúde. Teremos variáveis categóricas e contínuas.\n",
    "\n",
    "Para as variáveis categóricas, vamos ver como aplicar `OneHotEncoding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T14:03:01.626408Z",
     "start_time": "2021-06-12T14:03:01.354083Z"
    },
    "id": "bAIXf9So4IOu"
   },
   "outputs": [],
   "source": [
    "gasto = spark.read.csv('gasto.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDlczX-44IOw"
   },
   "source": [
    "Exiba as cinco primeiras linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "0fPPxWPV4IOx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gasto.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4WMSIyy4IOx"
   },
   "source": [
    "Exiba o schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:14:37.706329Z",
     "start_time": "2021-06-06T21:14:37.702193Z"
    },
    "id": "CDmFGv9-4IOy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- children: integer (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- charges: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gasto.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLRVyTei4IOz"
   },
   "source": [
    "Separe agora em treino (70%) e teste (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:14:53.430341Z",
     "start_time": "2021-06-06T21:14:53.422564Z"
    },
    "id": "Uvzhoq3J4IO0"
   },
   "outputs": [],
   "source": [
    "train, test = gasto.randomSplit([0.7,0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytKyoHtL4IO1"
   },
   "source": [
    "Vamos agora definir as variáveis que são categóricas e quais são numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:15:19.826193Z",
     "start_time": "2021-06-06T21:15:19.823315Z"
    },
    "id": "uqfwNkFe4IO2"
   },
   "outputs": [],
   "source": [
    "numeric_cols = [\"age\",\"bmi\",\"children\"]\n",
    "categorical_cols = [\"sex\", \"smoker\",\"region\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmnUKQdU4IO3"
   },
   "source": [
    "Para fazer OneHotEncoder no Spark, primeiro precisamos transformar valores (`yes/no`) em números (`0/1`). Para isso temos que usar duas funções `StringIndexer` (que irá converter rótulos em valores) e posteriormente a `OneHotEncoder`. O resultado da `StringIndexer` é um vetor esparso. Você sabe dizer a utilidade disso?\n",
    "\n",
    "\n",
    "Exemplo de um vetor esparso:\n",
    "\n",
    "```\n",
    "DenseVector(0, 0, 0, 7, 0, 2, 0, 0, 0, 0)\n",
    "SparseVector(10, [3, 5], [7, 2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:17:56.112063Z",
     "start_time": "2021-06-06T21:17:56.109318Z"
    },
    "id": "_AUPac8l4IO6"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0mya8M04IO7"
   },
   "source": [
    "Como sempre temos colunas como `input` e novas colunas como `output`, vamos definir o nome das colunas de output para cada uma das funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:18:34.793630Z",
     "start_time": "2021-06-06T21:18:34.790520Z"
    },
    "id": "r92almba4IO8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'smoker', 'region']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:18:35.700901Z",
     "start_time": "2021-06-06T21:18:35.697878Z"
    },
    "id": "fD4hxOBu4IO9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sexIndex', 'smokerIndex', 'regionIndex']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexOutputCols = [x+\"Index\" for x in categorical_cols]\n",
    "indexOutputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sexOHE', 'smokerOHE', 'regionOHE']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotOutputCols = [x+\"OHE\" for x in categorical_cols]\n",
    "oneHotOutputCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ahf46ER34IO-"
   },
   "source": [
    "Agora vamos criar nosso StringIndexer.\n",
    "\n",
    "**Pergunta**: o que fazemos quando indexamos no treino e no teste há um valor desconhecido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:19:25.780358Z",
     "start_time": "2021-06-06T21:19:25.774761Z"
    },
    "id": "FxztPCjF4IPA"
   },
   "outputs": [],
   "source": [
    "strIndexer = StringIndexer(inputCols = categorical_cols,\n",
    "                           outputCols = indexOutputCols,\n",
    "                           handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9oXX1Km4IPC"
   },
   "source": [
    "E agora criamos nosso `OneHotEncoder`.\n",
    "\n",
    "**Pergunta**: qual deve ser o input do OneHotEncoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:20:00.596765Z",
     "start_time": "2021-06-06T21:20:00.590343Z"
    },
    "id": "83HZG1CR4IPD"
   },
   "outputs": [],
   "source": [
    "oneHotEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
    "                              outputCols=oneHotOutputCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WU11yfkr4IPE"
   },
   "source": [
    "E também precisamos definir todas as colunas que serão usadas no vector que representará as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:20:23.990950Z",
     "start_time": "2021-06-06T21:20:23.988306Z"
    },
    "id": "1b4lvltC4IPG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'bmi', 'children', 'sexOHE', 'smokerOHE', 'regionOHE']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemblerInputs = numeric_cols + oneHotOutputCols\n",
    "assemblerInputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD_-s9do4IPH"
   },
   "source": [
    "Criamos o `VectorAssembler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:20:41.037499Z",
     "start_time": "2021-06-06T21:20:41.032027Z"
    },
    "id": "rn8rGy5_4IPI"
   },
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs,\n",
    "                               outputCol=\"Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecgOy1Rf4IPJ"
   },
   "source": [
    "Vamos ver se você entendeu: Obtenha o resultado do oneEncoder para o conjunto de treino. Selecione apenas as 20 primeiras linhas, com as colunas `region`, `regionIndex` e `regionOHE` para verificar o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:22:10.743490Z",
     "start_time": "2021-06-06T21:22:10.478279Z"
    },
    "id": "coji58kF4IPL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+\n",
      "|   region|regionIndex|    regionOHE|\n",
      "+---------+-----------+-------------+\n",
      "|southeast|        0.0|(3,[0],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|southeast|        0.0|(3,[0],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|southeast|        0.0|(3,[0],[1.0])|\n",
      "|southeast|        0.0|(3,[0],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|southeast|        0.0|(3,[0],[1.0])|\n",
      "|southeast|        0.0|(3,[0],[1.0])|\n",
      "|southeast|        0.0|(3,[0],[1.0])|\n",
      "|southeast|        0.0|(3,[0],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|southeast|        0.0|(3,[0],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "|northeast|        1.0|(3,[1],[1.0])|\n",
      "+---------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(oneHotEncoder.fit(strIndexer.fit(train).transform(train))\n",
    " .transform(strIndexer.fit(train).transform(train))\n",
    " .select(\"region\",\"regionIndex\",\"regionOHE\")\n",
    " .show(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PevWvvxf4IPM"
   },
   "source": [
    "Criamos agora nosso modelo de regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:22:27.138181Z",
     "start_time": "2021-06-06T21:22:27.122548Z"
    },
    "id": "jWfX2Tex4IPO"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol=\"charges\",\n",
    "                      featuresCol=\"Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyPwDKr74IPP"
   },
   "source": [
    "Criamos também nosso pipeline, composto pelos estágios:\n",
    "- stringIndexer\n",
    "- oheEncoder\n",
    "- vecAssembler\n",
    "- lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:23:01.905665Z",
     "start_time": "2021-06-06T21:23:01.902505Z"
    },
    "id": "Ae-LzARx4IPP"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[strIndexer,oneHotEncoder,\n",
    "                            vecAssembler,lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tjTivDw4IPQ"
   },
   "source": [
    "Aplicamos fit e, posteriormente, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:23:14.163779Z",
     "start_time": "2021-06-06T21:23:13.771750Z"
    },
    "id": "9gifS1wS4IPR"
   },
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:23:14.241277Z",
     "start_time": "2021-06-06T21:23:14.196299Z"
    },
    "id": "_O5TRADe4IPS"
   },
   "outputs": [],
   "source": [
    "pred = pipelineModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:23:16.761032Z",
     "start_time": "2021-06-06T21:23:16.671711Z"
    },
    "id": "APm_EY7-4IPT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------------------+-----------+------------------+\n",
      "|age|   sex|smoker|            Features|    charges|        prediction|\n",
      "+---+------+------+--------------------+-----------+------------------+\n",
      "| 18|female|    no|[18.0,24.09,1.0,0...|  2201.0971|   568.92382288308|\n",
      "| 18|female|   yes|(8,[0,1,2,5],[18....| 18223.4512|25977.071474826116|\n",
      "| 18|female|    no|(8,[0,1,4,6],[18....|7323.734819| 3049.623568745882|\n",
      "| 18|female|    no|(8,[0,1,4,6],[18....| 2203.47185| 3383.684533991961|\n",
      "| 18|female|    no|(8,[0,1,4,5],[18....|  1622.1885|2599.1639479576534|\n",
      "+---+------+------+--------------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.select(\"age\",\"sex\",\"smoker\",\n",
    "            \"Features\",\"charges\",\n",
    "            \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wsAfMIk4IPT"
   },
   "source": [
    "Como avaliar agora um modelo que é um pipeline. para esse caso, temos que construir um objeto da classe `RegressionEvaluator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:23:50.115221Z",
     "start_time": "2021-06-06T21:23:50.108895Z"
    },
    "id": "bLlrUK4S4IPV"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:23:51.710396Z",
     "start_time": "2021-06-06T21:23:51.631810Z"
    },
    "id": "DQT5yaWs4IPW"
   },
   "outputs": [],
   "source": [
    "regresEval = RegressionEvaluator(\n",
    "            predictionCol = \"prediction\",\n",
    "            labelCol=\"charges\",\n",
    "            metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5525.14\n"
     ]
    }
   ],
   "source": [
    "rmse = regresEval.evaluate(pred)\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T12:11:35.142528Z",
     "start_time": "2021-06-06T12:11:35.139809Z"
    },
    "id": "QtRe1FUK4IPW"
   },
   "source": [
    "# Salvando o modelo\n",
    "\n",
    "É uma boa prática salvar seu modelo para utilizar em outros momentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T20:43:25.733974Z",
     "start_time": "2021-06-06T20:43:24.402196Z"
    },
    "id": "1Bz7q6Gl4IPX"
   },
   "outputs": [],
   "source": [
    " pipelineModel.write().overwrite().save(\"./lr-pipelineModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuP7ZFwv4IPY"
   },
   "source": [
    "# Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T20:46:12.796160Z",
     "start_time": "2021-06-06T20:46:12.793330Z"
    },
    "id": "jJPcu-LU4IPZ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T20:46:29.706978Z",
     "start_time": "2021-06-06T20:46:28.045238Z"
    },
    "id": "kDt7LnM04IPa"
   },
   "outputs": [],
   "source": [
    "model = PipelineModel.load(\"./lr-pipelineModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexerModel: uid=StringIndexer_4499c63a02ec, handleInvalid=skip, numInputCols=3, numOutputCols=3,\n",
       " OneHotEncoderModel: uid=OneHotEncoder_ec77508b9b00, dropLast=true, handleInvalid=error, numInputCols=3, numOutputCols=3,\n",
       " VectorAssembler_3c296b015721,\n",
       " LinearRegressionModel: uid=LinearRegression_45da7b2ccb27, numFeatures=8]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O38W9SOF4IPb"
   },
   "source": [
    "# Otimização de hiperparâmetros e Validação Cruzada\n",
    "\n",
    "Vamos construir um modelo para nosso problema em questão agora fazendo uso de um `RandomForestRegressor`. Vamos querer otimizar 2 hiperparâmetros (`maxDepth` e `numTrees`), e obter seus valores a partir de um processo de validação cruzada com 5-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:25:19.942667Z",
     "start_time": "2021-06-06T21:25:19.940056Z"
    },
    "id": "nN2iDiY24IPc"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:25:23.396723Z",
     "start_time": "2021-06-06T21:25:23.389628Z"
    },
    "id": "o4rtFC594IPc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:25:24.618745Z",
     "start_time": "2021-06-06T21:25:24.609809Z"
    },
    "id": "hFd7h-GT4IPd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVnZbXqG4IPe"
   },
   "source": [
    "Para executar o grid, precisamos criar um objeto da classe `ParamGridBuilder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:25:49.535965Z",
     "start_time": "2021-06-06T21:25:49.532349Z"
    },
    "id": "AbGjaoSD4IPf"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:25:49.965155Z",
     "start_time": "2021-06-06T21:25:49.961827Z"
    },
    "id": "W2MOMZny4IPg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1iBpPSq4IPg"
   },
   "source": [
    "E criamos também um `RegressionEvaluator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T20:53:15.723183Z",
     "start_time": "2021-06-06T20:53:15.716256Z"
    },
    "id": "_n6dpUBT4IPh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-KaM9-U4IPi"
   },
   "source": [
    "Para executar a validação cruzada, nós precisamos importar a função `CrossValidator` de `pyspark.ml.tuning`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:26:27.739846Z",
     "start_time": "2021-06-06T21:26:27.737219Z"
    },
    "id": "Ut2jFjMv4IPj"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T14:04:38.188419Z",
     "start_time": "2021-06-12T14:04:38.184766Z"
    },
    "id": "h9X4xToL4IPk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4Fx_xv84IPl"
   },
   "source": [
    "E podemos obter nosso modelo a partir do `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:27:19.826846Z",
     "start_time": "2021-06-06T21:26:44.901910Z"
    },
    "id": "tdskP9CV4IPm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6djEAKEV4IPn"
   },
   "source": [
    "E também podemos verificar todas as trials feitas no processo de otimização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:27:19.848238Z",
     "start_time": "2021-06-06T21:27:19.835760Z"
    },
    "id": "AniS_s0R4IPq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T21:27:20.069919Z",
     "start_time": "2021-06-06T21:27:19.850770Z"
    },
    "id": "l1vJ3Ej_4IPr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PKPPxrd4IPr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNUh-HZi4IPs"
   },
   "source": [
    "# Link para referência adicional\n",
    "\n",
    "Vejam aqui um exemplo de um pipeline de **classificação**.\n",
    "\n",
    "https://swan-gallery.web.cern.ch/notebooks/SparkTraining/notebooks/ML_Demo1_Classifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-i1t84x4IPt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
