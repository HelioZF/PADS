{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVBZIPfYJiVT"
      },
      "source": [
        "Insper\n",
        "\n",
        "# Aula 6 - DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:17:23.734268Z",
          "start_time": "2021-05-21T00:17:16.123247Z"
        },
        "id": "b2OJVWpSJiVf"
      },
      "outputs": [],
      "source": [
        "# Criar a sessao do Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "            .builder \\\n",
        "            .master(\"local[*]\") \\\n",
        "            .appName(\"Michel_DF\") \\\n",
        "            .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:17:26.088238Z",
          "start_time": "2021-05-21T00:17:26.064592Z"
        },
        "id": "X_uHmyPbJiVm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "817eeb7f-cad4-4008-8665-7b5a66146f06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d0460f5a230>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b6b29c9a94eb:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Michel_DF</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:17:27.899075Z",
          "start_time": "2021-05-21T00:17:27.891439Z"
        },
        "id": "DJONGIw8JiVp"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5rPPVs9JiVq"
      },
      "source": [
        "Até agora vimos trabalhando com a estrutura base do Spark, as RDDs. Contudo, essas estruturas são trabalhosas e requerem o tratamento manual de tipos de dados bem como a interpretação constante dos dados posicionais na RDD.\n",
        "\n",
        "É possível simplificar nosso trabalho com o uso de camadas novas e mais elevadas do Spark.\n",
        "\n",
        "\n",
        "Existe uma série de funções para a criação e a criação e manipulação destas novas estruturas de dados. Vamos começar investigando os DataFrames, inspirados na biblioteca Pandas do Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSFf5T_7JiVs"
      },
      "source": [
        "## createDataFrame()\n",
        "Para criar um DataFrame a partir de uma RDD, podemos utilizar a função `createDataFrame(RDD)`. É importante notar que o ponto de entrada das APIs de dados estruturados não é mais o `sparkContext`, mas diretamente a `SparkSession` acessível a partir da nossa variável `spark`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:20:53.995743Z",
          "start_time": "2021-05-21T00:20:53.960306Z"
        },
        "id": "f6wzQG_wJiVu"
      },
      "outputs": [],
      "source": [
        "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:20:59.480156Z",
          "start_time": "2021-05-21T00:20:59.344274Z"
        },
        "id": "OYIgjGJpJiVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0037aa-c91c-4e63-b50f-bf0102c4541d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Finance', 10), ('Marketing', 20), ('Sales', 30), ('IT', 40)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "dept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:21:19.780167Z",
          "start_time": "2021-05-21T00:21:18.710684Z"
        },
        "id": "EFaEkkXaJiVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6985607f-c133-4a04-dfe2-c359389cf0bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+\n",
            "|Department| ID|\n",
            "+----------+---+\n",
            "|   Finance| 10|\n",
            "| Marketing| 20|\n",
            "|     Sales| 30|\n",
            "|        IT| 40|\n",
            "+----------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.createDataFrame(dept, [\"Department\", \"ID\"])\n",
        "\n",
        "# Mostrar o DataFrame\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:21:22.105019Z",
          "start_time": "2021-05-21T00:21:22.095313Z"
        },
        "id": "NDYRgWy6JiVy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:22:41.521281Z",
          "start_time": "2021-05-21T00:22:41.510506Z"
        },
        "id": "sT_f_nPYJiVz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u2_ExutJiV0"
      },
      "source": [
        "Verificamos que a variável é do tipo DataFrame com colunas com nome `_1, _2,` e diferentes tipos, já __inferidos__ pelo Spark na criação do DataFrame a partir da RDD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apT8qjmtJiV2"
      },
      "source": [
        "## take()\n",
        "Podemos então utilizar a função take para verificar nosso DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:23:11.797527Z",
          "start_time": "2021-05-21T00:23:11.583109Z"
        },
        "id": "ALatHfQLJiV4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl_vUx7TJiV5"
      },
      "source": [
        "É interessante observar que a função nos mostra uma RDD e não um DataFrame. Essa RDD é composta de objetos do tipo Row, ou então linha. Isso é, um DataFrame nada mais é do que uma RDD onde cada elemento é uma linha de uma tabela com suas diferentes colunas.\n",
        "\n",
        "Diferentemente das RDDs padrões, contudo, os objetos Row grava consigo os nomes e os tipos das colunas e o Spark mantém a gestão garantindo que um mesmo DataFrame seja composto de linhas do mesmo tipo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6qXdyEUJiV8"
      },
      "source": [
        "## Row()\n",
        "\n",
        "Podemos manualmente criar uma linha, a partir da classe Row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:24:12.314546Z",
          "start_time": "2021-05-21T00:24:12.310669Z"
        },
        "id": "C9CLvHlOJiV9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klGT7PLMJiV9"
      },
      "source": [
        "Para isso precisamos nomear as colunas e seus valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:24:33.556002Z",
          "start_time": "2021-05-21T00:24:33.550280Z"
        },
        "id": "ErNt0M6WJiV-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvt_OY0kJiV_"
      },
      "source": [
        "Mais tarde entenderemos como concatenar diferentes objetos Row em um DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phDabM0bJiWA"
      },
      "source": [
        "## asDict()\n",
        "\n",
        "Podemos transformar objetos do tipo Row em dicionários no python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:25:04.122126Z",
          "start_time": "2021-05-21T00:25:04.020307Z"
        },
        "id": "vFzubGeLJiWB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0szOjGQsJiWC"
      },
      "source": [
        "Para isso, vamos inicialmente guardar duas linhas de nosso DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:25:20.921552Z",
          "start_time": "2021-05-21T00:25:20.820444Z"
        },
        "id": "Re124bTZJiWD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-TnIElGJiWD"
      },
      "source": [
        "Na sequencia utilizamos a função asDict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:25:45.766270Z",
          "start_time": "2021-05-21T00:25:45.760421Z"
        },
        "id": "n9Dnt2UQJiWE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpd9rCfxJiWF"
      },
      "source": [
        "Com isso podemos acessar os valores de cada coluna normalmente como um dicionário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:26:23.845737Z",
          "start_time": "2021-05-21T00:26:23.840244Z"
        },
        "id": "g7HyXx5VJiWF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B1Oe4q8JiWG"
      },
      "source": [
        "## RDD\n",
        "O atributo rdd do DataFrame também nos dá acesso direto à RDD fundamental que constrói o DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:26:43.660095Z",
          "start_time": "2021-05-21T00:26:43.630309Z"
        },
        "id": "JDUpa3ZZJiWH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxaC9-kxJiWH"
      },
      "source": [
        "Nessa RDD podemos aplicar todas as transformações e ações que aprendemos, desde que respeitando o tipo do elemento Row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:27:07.222509Z",
          "start_time": "2021-05-21T00:27:07.000299Z"
        },
        "id": "r3osxoEtJiWI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcitdRwlJiWJ"
      },
      "source": [
        "# Acessando o DataFrame\n",
        "A ideia de termos um DataFrame, contudo, é não precisarmos operar diretamente nas RDDs. Para isso existe um conjunto de funções de acesso direto ao DataFrame. Como estas funções operam intrinsecamente em RDDs, elas também são transformações e ações.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d164XEI9JiWK"
      },
      "source": [
        "## show()\n",
        "A ação show() nos permite olhar o DataFrame como uma tabela, muito mais próximo do Pandas DataFrame. Cuidado, contudo, com o desejo de olhar o DataFrame completo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:27:44.225248Z",
          "start_time": "2021-05-21T00:27:44.041299Z"
        },
        "id": "F6LPgo4zJiWL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iuqddWyJiWL"
      },
      "source": [
        "## printSchema()\n",
        "\n",
        "A ação show() não nos mostra claramente qual é o tipo dos dados envolvidos (similar a dtypes). Para isso, podemos imprimir o Schema do DataFrame.\n",
        "\n",
        "O Schema é a definição do tipo de dado de cada coluna. É importante notar que o Spark inferiu esses dados a partir da RDD. O Spark infere a partir do primeiro elemento nos dados. Portanto, é importante que na leitura de arquivos, caso a inferência seja utilizada, garantir que a primeira linha do arquivo possua o tipo correto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:28:06.542170Z",
          "start_time": "2021-05-21T00:28:06.530567Z"
        },
        "id": "bPtzOWSiJiWM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W24MBB2lJiWN"
      },
      "source": [
        "## dtypes\n",
        "\n",
        "Podemos também utilizar o atributo dtypes para mostrar o tipo de cada coluna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:28:24.737418Z",
          "start_time": "2021-05-21T00:28:24.731344Z"
        },
        "id": "FcOetGJYJiWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f239adee-837b-4a61-965a-f4b09dd25c0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Department', 'string'), ('ID', 'bigint')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df.printSchema())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFBOO1Ww1CvS",
        "outputId": "0961761f-ffbd-4c35-ac7c-be3f95e4ce92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Department: string (nullable = true)\n",
            " |-- ID: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfJ9BdkAJiWO"
      },
      "source": [
        "# Definindo o Schema\n",
        "Idealmente, quando operando em grandes massas de dados, a inferência do tipo pela primeira linha não é adequada e utilizamos como boa prática a definição manual do schema. Para isso precisamos utilizar os tipos de dados nativos do Spark que são convertidos para e de tipos python pela API pyspark.\n",
        "\n",
        "Para isso importamos os tipos do spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:28:43.544586Z",
          "start_time": "2021-05-21T00:28:43.540393Z"
        },
        "id": "YfHDpfnUJiWP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLpeDCtyJiWQ"
      },
      "source": [
        "## StructType(), StructField(), IntegerType(), StringType(), FloatType()\n",
        "Cada tipo de variável é na verdade um objeto de uma classe. Então acessamos estes objetos para instanciar e para identificar os tipos de cada variável.\n",
        "\n",
        "O Schema de um DataFrame é definido como um objeto StructType (similar a uma lista ou tupla) com campos do tipo StructField(). Cada campo (StructField) possui um nome, um tipo (objeto do tipo no spark) e um flag se é permitida a existência de nulos.\n",
        "\n",
        "Assim, podemos definir explicitametne um Schema para nosso DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:31:14.074827Z",
          "start_time": "2021-05-21T00:31:14.070260Z"
        },
        "id": "Nz_YqnkFJiWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168be4d9-acda-4d33-e1d1-17be5907aafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+\n",
            "|Department| ID|\n",
            "+----------+---+\n",
            "|   Finance| 10|\n",
            "| Marketing| 20|\n",
            "|     Sales| 30|\n",
            "|        IT| 40|\n",
            "+----------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
        "schema = StructType([\n",
        "    StructField(\"Department\", StringType(), True),\n",
        "    StructField(\"ID\", LongType(), True)\n",
        "])\n",
        "\n",
        "# Criar o DataFrame com o esquema definido\n",
        "df_schema = spark.createDataFrame(dept, schema)\n",
        "df_schema.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZaZj0VMJiWR"
      },
      "source": [
        "Na sequencia, atribuímos o nosso schema ao DataFrame na sua criação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:31:14.959049Z",
          "start_time": "2021-05-21T00:31:14.920363Z"
        },
        "id": "c4WQVLM7JiWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19476b9c-03de-49bb-9f49-bdf7a2ab1a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Department: string (nullable = true)\n",
            " |-- ID: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_schema.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "011z0FrKJiWT"
      },
      "source": [
        "Podemos então olhar nosso DataFrame e verificar que as colunas agora vêm identificadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:31:16.272213Z",
          "start_time": "2021-05-21T00:31:16.090423Z"
        },
        "id": "fGc42ofXJiWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f739c716-c42a-40ea-b5d2-e3087f4fe91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+\n",
            "|Department| ID|\n",
            "+----------+---+\n",
            "|   Finance| 10|\n",
            "| Marketing| 20|\n",
            "|     Sales| 30|\n",
            "|        IT| 40|\n",
            "+----------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_schema.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:31:27.848904Z",
          "start_time": "2021-05-21T00:31:27.843263Z"
        },
        "id": "Y4aMBaG3JiWU"
      },
      "source": [
        "Podemos também verificar o Schema do DataFrame com as características que definimos anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:31:39.338187Z",
          "start_time": "2021-05-21T00:31:39.333233Z"
        },
        "id": "T_Fu_foZJiWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9cf6f9-b774-42bd-ddcc-fa6743f46301"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Department', 'ID']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df_schema.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_schema.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mepXErRy4ohh",
        "outputId": "0ad0e152-77c9-4dc1-8ed5-25cf0d3f838b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Department='Finance', ID=10), Row(Department='Marketing', ID=20)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npddbeDlJiWV"
      },
      "source": [
        "# Operações básicas com colunas\n",
        "\n",
        "A exemplo do Pandas DataFrame, temos à nossa disposição uma série de transformações e ações que nos permite operar sobre o Spark DataFrame. Veremos a seguir as operações em colunas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhpNDcVLJiWW"
      },
      "source": [
        "## columns\n",
        "O atributo columns retorna, a exemplo do Pandas, uma lista com o nome das colunas. Contudo, diferente do Pandas, não é possível sobrescrever este atributo diretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:32:11.765697Z",
          "start_time": "2021-05-21T00:32:11.760307Z"
        },
        "id": "UT9n7-MQJiWX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clf8dytvJiWX"
      },
      "source": [
        "## withColumnRenamed()\n",
        "Para renomear uma coluna utilizamos a função withColumnRenamed(). Esta função opera em uma coluna por vez. Assim, podemos utilizar um laço para renomear todas as colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:32:42.550595Z",
          "start_time": "2021-05-21T00:32:42.531472Z"
        },
        "id": "FePzuZMQJiWY"
      },
      "outputs": [],
      "source": [
        "for old_col, new_col in zip(df_schema.columns, ['dept_name', 'dept_id']):\n",
        "    df_schema = df_schema.withColumnRenamed(old_col, new_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:32:46.975020Z",
          "start_time": "2021-05-21T00:32:46.790250Z"
        },
        "id": "seWCGQciJiWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38d5eb4-0364-428b-ed45-1fa8b4f6777c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|  Finance|     10|\n",
            "|Marketing|     20|\n",
            "|    Sales|     30|\n",
            "|       IT|     40|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_schema.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-2NQ4U0JiWa"
      },
      "source": [
        "## drop()\n",
        "Podemos descartar colunas usando a função .drop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:33:07.468100Z",
          "start_time": "2021-05-21T00:33:07.230097Z"
        },
        "id": "Dtqt1X3jJiWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbbfb3b-072f-4534-94f5-4b55e9890196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|dept_name|\n",
            "+---------+\n",
            "|  Finance|\n",
            "|Marketing|\n",
            "|    Sales|\n",
            "|       IT|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_schema.drop('dept_id').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG4j9r1uJiWc"
      },
      "source": [
        "## Acessando colunas\n",
        "Para acessar as colunas de um DataFrame, podemos utilizar a mesma notação python. Observe, contudo, que as colunas são representadas como objetos e, assim, o acesso à coluna não retorna automaticamente os dados existentes nela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:33:32.526381Z",
          "start_time": "2021-05-21T00:33:32.450232Z"
        },
        "id": "5YYiWqGuJiWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b45bf3-2124-4e87-e3ff-14b3c2f0311b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'dept_id'>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "df_schema[\"dept_id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:33:42.625523Z",
          "start_time": "2021-05-21T00:33:42.570266Z"
        },
        "id": "Nt16jBv-JiWe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgDh9C7XJiWe"
      },
      "source": [
        "## select()\n",
        "Para acessar os dados de uma coluna específica, precisamos utilizar a transformação select() seguida de uma ação show(). Esta transformação é similiar ao SELECT em SQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:33:58.099007Z",
          "start_time": "2021-05-21T00:33:57.920370Z"
        },
        "id": "s9KV3cCSJiWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68be30c-5d70-4cbc-d2af-a608a280f2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|dept_id|\n",
            "+-------+\n",
            "|     10|\n",
            "|     20|\n",
            "|     30|\n",
            "|     40|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_schema.select('dept_id').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VZH0IMnJiWg"
      },
      "source": [
        "## Case sensitivity\n",
        "Observe que a exemplo do SQL, DataFrames em Spark não são naturalmente sensíveis ao caso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:34:15.501565Z",
          "start_time": "2021-05-21T00:34:15.320632Z"
        },
        "id": "bCDWUYJoJiWg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:34:34.631098Z",
          "start_time": "2021-05-21T00:34:34.440421Z"
        },
        "id": "PM0zteTYJiWh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfWrNMcWJiWi"
      },
      "source": [
        "# Operações básicas com linhas\n",
        "Da mesma forma que temos operações com colunas, temos operações com linhas.\n",
        "\n",
        "## limit()\n",
        "A transformação limit(LIM) nos permite limitar um número de registros (linhas no DataFrame) a ser retornado. POdemos concatenar com .collect() e temos o DataFrame no formato de RDD.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:35:13.374964Z",
          "start_time": "2021-05-21T00:35:13.200477Z"
        },
        "id": "Yn6WIpLtJiWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90340591-234e-49c4-f301-2a60323e1e3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(dept_name='Finance', dept_id=10), Row(dept_name='Marketing', dept_id=20)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "df_schema.limit(2).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh8SZ_kEJiWj"
      },
      "source": [
        "Com isso podemos reduzir o número de linhas do nosso DataFrame para aumentar a velocidade do nosso trabalho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:35:36.000515Z",
          "start_time": "2021-05-21T00:35:35.990571Z"
        },
        "id": "MIJs_UuTJiWk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntr6oazvJiWl"
      },
      "source": [
        "## filter() - filtrando linhas\n",
        "A transformação filter() nos permite filtrar linhas com base em condições especificadas sobre colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:36:02.834516Z",
          "start_time": "2021-05-21T00:36:02.453420Z"
        },
        "id": "_EiB-3Q1JiWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02e9578-7bfa-4b94-8230-4f9449c6173b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|  Finance|     10|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_schema.filter(df_schema.dept_name == 'Finance').show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_schema.filter(df_schema.dept_id == 10).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjpFCvGx9f1i",
        "outputId": "07e68968-8aca-45ab-bc00-ff4145ee38f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|  Finance|     10|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3ccByLcJiWn"
      },
      "source": [
        "## where() - filtrando linhas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:36:17.736282Z",
          "start_time": "2021-05-21T00:36:17.730335Z"
        },
        "id": "7e9gZNOhJiWo"
      },
      "source": [
        "Para manter a similaridade como o SQL, a transformação filter() também pode ser acessada através de seu apelido (alias) where()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:36:36.380428Z",
          "start_time": "2021-05-21T00:36:36.170693Z"
        },
        "id": "XLX2n7KwJiWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e30fa43-3ec2-49dc-856a-bae09319e556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|  Finance|     10|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_schema.where(df_schema.dept_name == 'Finance').show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_schema.where(\"dept_name = 'Finance'\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA1c1QUU9wgt",
        "outputId": "93a7b114-de59-4697-ce5f-f332dbf62814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|  Finance|     10|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELnOoY6qJiWr"
      },
      "source": [
        "## distinct() - filtrando valores distintos\n",
        "Utilizamos a transformação distinct() para selecionar apenas os valores distintos de uma coluna específica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:37:01.885896Z",
          "start_time": "2021-05-21T00:37:01.240361Z"
        },
        "id": "HUnW0ca8JiWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c771b2ad-512d-48e0-bb73-00bd7141483d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|dept_name|\n",
            "+---------+\n",
            "|  Finance|\n",
            "|Marketing|\n",
            "|    Sales|\n",
            "|       IT|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_schema.select('dept_name').distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upSmk_q8JiWv"
      },
      "source": [
        "## union() - concatenando linhas\n",
        "Para concatenar linhas no DataFrame, precisamos criar uma RDD com objetos do tipo Row e Schema idêntico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:38:28.674744Z",
          "start_time": "2021-05-21T00:38:28.670193Z"
        },
        "id": "ZurNo4QdJiWw"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "# Criar novas linhas usando Row\n",
        "new_rows = [Row(dept_name=\"Production\", dept_id=50), Row(dept_name=\"IT\", dept_id=60)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:38:34.775686Z",
          "start_time": "2021-05-21T00:38:34.770448Z"
        },
        "id": "poCgsFKRJiWx"
      },
      "outputs": [],
      "source": [
        "rdd_row = sc.parallelize(new_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyzhOqhZJiWy"
      },
      "source": [
        "Transformamos essa lista em uma RDD, usando parallelize(), da mesma forma que fizemos anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:39:00.869358Z",
          "start_time": "2021-05-21T00:39:00.860407Z"
        },
        "id": "26zYJRg-JiWz"
      },
      "outputs": [],
      "source": [
        "newDF = spark.createDataFrame(rdd_row,schema=schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rbQwTPDJiW0"
      },
      "source": [
        "Por fim, criamos o DataFrame, definindo o Schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:39:28.912117Z",
          "start_time": "2021-05-21T00:39:28.870363Z"
        },
        "id": "Gg295LwDJiW2"
      },
      "outputs": [],
      "source": [
        "sdf1 = df_schema.union(newDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:39:35.790342Z",
          "start_time": "2021-05-21T00:39:35.630421Z"
        },
        "id": "NJiZp7wbJiW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6febf8ad-b13d-4f36-ba7a-592bbbeb343c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+\n",
            "| dept_name|dept_id|\n",
            "+----------+-------+\n",
            "|   Finance|     10|\n",
            "| Marketing|     20|\n",
            "|     Sales|     30|\n",
            "|        IT|     40|\n",
            "|Production|     50|\n",
            "|        IT|     60|\n",
            "+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sdf1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfF00auYJiW3"
      },
      "source": [
        "Podemos então concatenar nosso novo DataFrame ao DataFrame antigo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:40:02.349584Z",
          "start_time": "2021-05-21T00:40:02.283006Z"
        },
        "id": "e-azi7fSJiW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2599cd4c-3283-41e3-9cb8-f7505ec6ee17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "| dept_name|\n",
            "+----------+\n",
            "|   Finance|\n",
            "| Marketing|\n",
            "|     Sales|\n",
            "|        IT|\n",
            "|Production|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Selecionar valores distintos na coluna dept_name\n",
        "sdf1.select(\"dept_name\").distinct().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:40:11.145556Z",
          "start_time": "2021-05-21T00:40:10.701273Z"
        },
        "id": "NfdvzsKOJiW6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgLqF_2XJiW6"
      },
      "source": [
        "## orderBy() - ordenando linhas\n",
        "Com a transformação orderBy() podemos ordenar as linhas do DataFrame. Para isso, precisamos utilizar os métodos .asc() ou .desc() na coluna chave, indicando a ordem desejada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:40:48.398791Z",
          "start_time": "2021-05-21T00:40:48.000270Z"
        },
        "id": "kq4087edJiW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619cd4e8-11f7-4c8c-e23d-6a01041bd1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+\n",
            "| dept_name|dept_id|\n",
            "+----------+-------+\n",
            "|   Finance|     10|\n",
            "| Marketing|     20|\n",
            "|     Sales|     30|\n",
            "|        IT|     40|\n",
            "|Production|     50|\n",
            "|        IT|     60|\n",
            "+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sdf1.orderBy(sdf1.dept_id.asc()).show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf1.orderBy(sdf1.dept_id.desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJHpOyPVLMkI",
        "outputId": "798b8504-fe40-4489-b649-7aae0b9e3e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+\n",
            "| dept_name|dept_id|\n",
            "+----------+-------+\n",
            "|        IT|     60|\n",
            "|Production|     50|\n",
            "|        IT|     40|\n",
            "|     Sales|     30|\n",
            "| Marketing|     20|\n",
            "|   Finance|     10|\n",
            "+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFe0a2vPJiW9"
      },
      "source": [
        "# pyspark.sql.functions\n",
        "Existe uma série de funções que facilitam a manipulação de DataFrames. Elas estão disponíveis no pacote pyspark.sql.functions e podem ser investigadas na referência abaixo:\n",
        "\n",
        "http://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html#module-pyspark.sql.functions\n",
        "\n",
        "Podemos importá-las todas através da linha de comando abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:41:27.216458Z",
          "start_time": "2021-05-21T00:41:27.200290Z"
        },
        "id": "ajn3Fu4ZJiW-"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as sf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsXz_F4DJiW_"
      },
      "source": [
        "## lit() - criando colunas\n",
        "Como visto anteriormente, o Spark possui tipos próprios de dados com correspondência com o Python. Se quisermos criar uma coluna constante, podemos evitar o trabalho de criar a coluna em Python e transformá-la, utilizando a função lit(val) que cria uma coluna de literais (constantes) val."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:41:44.868609Z",
          "start_time": "2021-05-21T00:41:44.820337Z"
        },
        "id": "jB0N2-IsJiXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd942ce-ff7c-4833-d17e-2a5d24e5c3e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'5'>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "sf.lit(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuIFQ959JiXB"
      },
      "source": [
        "## withColumn() - adicionando colunas\n",
        "\n",
        "Para isso, precisamos concatenar uma coluna de literais. Isso é feito com a transformação withColumn(nome, nova_col)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:42:40.713566Z",
          "start_time": "2021-05-21T00:42:40.373309Z"
        },
        "id": "fo02aqO6JiXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1672499-5dd2-4fe2-9f13-d1ab4b8a5126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+-------+\n",
            "| dept_name|dept_id|new_col|\n",
            "+----------+-------+-------+\n",
            "|   Finance|     10|      5|\n",
            "| Marketing|     20|      5|\n",
            "|     Sales|     30|      5|\n",
            "|        IT|     40|      5|\n",
            "|Production|     50|      5|\n",
            "|        IT|     60|      5|\n",
            "+----------+-------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sdf1.withColumn('new_col', sf.lit(5)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hoqj5LzJiXE"
      },
      "source": [
        "## col() - acessando colunas\n",
        "\n",
        "Em alguns casos precisamos explicitar que desejamos acessar um objeto do tipo Column. Para isso temos à nossa disposição a função .col(nome)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:42:44.644237Z",
          "start_time": "2021-05-21T00:42:44.250259Z"
        },
        "id": "4oKyEFg1JiXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f585af5-058a-41a0-8ba5-3828056b8132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "| dept_name|\n",
            "+----------+\n",
            "|   Finance|\n",
            "| Marketing|\n",
            "|     Sales|\n",
            "|        IT|\n",
            "|Production|\n",
            "|        IT|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sdf1.select(sf.col('dept_name')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3tdTHvDJiXG"
      },
      "source": [
        "Observe que temos, com isso, diferentes formas de acessar colunas no select. Em alguns casos específicos será necessário optar pela menção explícita ao tipo do objeto usando .col()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:43:16.281709Z",
          "start_time": "2021-05-21T00:43:15.967344Z"
        },
        "id": "Y75w2diGJiXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c9d289-eb84-480c-c956-aedf56f0e0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|dept_id| dept_name|\n",
            "+-------+----------+\n",
            "|     10|   Finance|\n",
            "|     20| Marketing|\n",
            "|     30|     Sales|\n",
            "|     40|        IT|\n",
            "|     50|Production|\n",
            "|     60|        IT|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sdf1.select(sdf1.dept_id,sf.col('dept_name')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPZcGGYaJiXH"
      },
      "source": [
        "Podemos ainda acessar a RDD resultante da transformação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:43:53.141443Z",
          "start_time": "2021-05-21T00:43:52.861402Z"
        },
        "id": "e5KQRhetJiXI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0nLbwS1JiXI"
      },
      "source": [
        "## alias()\n",
        "\n",
        "A exemplo do SQL, podemos utilizar o método .alias() de uma coluna específica para renomear colunas rapidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:45:43.459353Z",
          "start_time": "2021-05-21T00:45:43.260528Z"
        },
        "id": "su8c3npDJiXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e444039-efe4-42e1-a505-5cccfe8036b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+--------------+\n",
            "| dept_name|dept_id|Indentificador|\n",
            "+----------+-------+--------------+\n",
            "|   Finance|     10|            10|\n",
            "| Marketing|     20|            20|\n",
            "|     Sales|     30|            30|\n",
            "|        IT|     40|            40|\n",
            "|Production|     50|            50|\n",
            "|        IT|     60|            60|\n",
            "+----------+-------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sdf1.select(\"*\",sf.col(\"dept_id\").alias(\"Indentificador\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf1.select(\"*\",sdf1[\"dept_id\"].alias(\"Indentificador\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_Dw_a0PNpTg",
        "outputId": "8c92e540-031b-471c-8bc9-ce00f2f7233f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+--------------+\n",
            "| dept_name|dept_id|Indentificador|\n",
            "+----------+-------+--------------+\n",
            "|   Finance|     10|            10|\n",
            "| Marketing|     20|            20|\n",
            "|     Sales|     30|            30|\n",
            "|        IT|     40|            40|\n",
            "|Production|     50|            50|\n",
            "|        IT|     60|            60|\n",
            "+----------+-------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YT0oBzTJiXK"
      },
      "source": [
        "# Expressões\n",
        "DataFrames são equivalentes de tabelas no Pandas e também de tabelas no SQL. Buscando manter compatibilidade com o SQL, expressões permitem que escrevamos algumas expressões simplificadas de SQL para operar no DataFrame.\n",
        "\n",
        "\n",
        "## expr()\n",
        "Para isso, utilizamos a função expr(). Podemos, por exemplo, renomear colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:54:44.670058Z",
          "start_time": "2021-05-21T00:54:43.897373Z"
        },
        "id": "6fnpe5maJiXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08508879-2911-4f63-eac7-73e34136f93d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|departamento|\n",
            "+------------+\n",
            "|     Finance|\n",
            "|   Marketing|\n",
            "|       Sales|\n",
            "|          IT|\n",
            "|  Production|\n",
            "|          IT|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sdf1.select(sf.expr(\"dept_name as departamento\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh5u383jJiXN"
      },
      "source": [
        "Podemos também operar sobre colunas diretamente, a exemplo do SQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:55:25.186146Z",
          "start_time": "2021-05-21T00:55:24.900466Z"
        },
        "id": "lQjHYGv9JiXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f5da49-f943-4e3a-b45e-312a89dba750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+-------+\n",
            "| dept_name|dept_id|novo_ID|\n",
            "+----------+-------+-------+\n",
            "|   Finance|     10|    1.0|\n",
            "| Marketing|     20|    2.0|\n",
            "|     Sales|     30|    3.0|\n",
            "|        IT|     40|    4.0|\n",
            "|Production|     50|    5.0|\n",
            "|        IT|     60|    6.0|\n",
            "+----------+-------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sdf1.select(\"*\",sf.expr(\"dept_id / 10\").alias(\"novo_ID\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYrlbN7qJiXQ"
      },
      "source": [
        "## selectExpr()\n",
        "\n",
        "Como a combinação de .select() e .expr() é muito comum, o spark já nos fornece um atalho: selectExpr()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:56:23.388730Z",
          "start_time": "2021-05-21T00:56:23.180428Z"
        },
        "id": "Xl5bL80IJiXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb2afe0-e1de-45a4-ab82-69a1294049be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+-------+\n",
            "| dept_name|dept_id|novo_ID|\n",
            "+----------+-------+-------+\n",
            "|   Finance|     10|    1.0|\n",
            "| Marketing|     20|    2.0|\n",
            "|     Sales|     30|    3.0|\n",
            "|        IT|     40|    4.0|\n",
            "|Production|     50|    5.0|\n",
            "|        IT|     60|    6.0|\n",
            "+----------+-------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sdf1.selectExpr(\"*\", \"dept_id / 10 as novo_ID\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEcimQS7JiXS"
      },
      "source": [
        "# Abrindo arquivos CSV\n",
        "Até agora trabalhamos com DataFrames criados manualmente a partir de uma RDD prévia. Podemos utilizar as funções do pacote .read do Spark para ler diretamente fontes de dados. Para carregar arquivos .csv usamos a função .csv.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4r4nxzzyu3u",
        "outputId": "6fd31c3e-dc7a-4c7f-f991-339a58a34a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-09 11:22:53--  https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261978986 (250M) [application/zip]\n",
            "Saving to: ‘ml-25m.zip’\n",
            "\n",
            "ml-25m.zip          100%[===================>] 249.84M  20.3MB/s    in 14s     \n",
            "\n",
            "2024-11-09 11:23:07 (18.3 MB/s) - ‘ml-25m.zip’ saved [261978986/261978986]\n",
            "\n",
            "Archive:  ml-25m.zip\n",
            "   creating: ml-25m/\n",
            "  inflating: ml-25m/tags.csv         \n",
            "  inflating: ml-25m/links.csv        \n",
            "  inflating: ml-25m/README.txt       \n",
            "  inflating: ml-25m/ratings.csv      \n",
            "  inflating: ml-25m/genome-tags.csv  \n",
            "  inflating: ml-25m/genome-scores.csv  \n",
            "  inflating: ml-25m/movies.csv       \n"
          ]
        }
      ],
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
        "!unzip ml-25m.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar a sessao do Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "            .builder \\\n",
        "            .master(\"local[*]\") \\\n",
        "            .appName(\"Michel_DF\") \\\n",
        "            .getOrCreate()"
      ],
      "metadata": {
        "id": "4VCV5j_dqsfk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T00:56:53.756026Z",
          "start_time": "2021-05-21T00:56:53.310648Z"
        },
        "id": "M0tznDXTJiXW"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('/content/ml-25m/ratings.csv', header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T19:53:47.626787Z",
          "start_time": "2021-05-20T19:53:47.565414Z"
        },
        "id": "HQpAU4oeJiXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb0fe52f-e5ad-49b6-8a5c-ff4dcf41b7d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(userId='1', movieId='296', rating='5.0', timestamp='1147880044'),\n",
              " Row(userId='1', movieId='306', rating='3.5', timestamp='1147868817'),\n",
              " Row(userId='1', movieId='307', rating='5.0', timestamp='1147868828'),\n",
              " Row(userId='1', movieId='665', rating='5.0', timestamp='1147878820'),\n",
              " Row(userId='1', movieId='899', rating='3.5', timestamp='1147868510')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.take(54)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, LongType, BooleanType, DoubleType, DoubleType, IntegerType"
      ],
      "metadata": {
        "id": "rA04gphtrcq5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colunas = [('user_id',IntegerType()),\n",
        "           ('movie_id',IntegerType()),\n",
        "           ('rating', DoubleType()),\n",
        "           ('timestamp',StringType())]"
      ],
      "metadata": {
        "id": "_wUOUH7Mrc2e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colunas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTwWoY32rc5l",
        "outputId": "0ceaa0f0-92c2-48f8-bfdc-9e5499050242"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('user_id', IntegerType()),\n",
              " ('movie_id', IntegerType()),\n",
              " ('rating', DoubleType()),\n",
              " ('timestamp', StringType())]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([StructField(colName,colType, True) for colName, colType in colunas])\n",
        "schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_cgjJqlrc8Y",
        "outputId": "324d0dca-5bad-44e0-d454-913d21fd6a5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('user_id', IntegerType(), True), StructField('movie_id', IntegerType(), True), StructField('rating', DoubleType(), True), StructField('timestamp', StringType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('/content/ml-25m/ratings.csv', header=True, schema = schema )"
      ],
      "metadata": {
        "id": "wrcl9fvkrc-t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Mc-9ObrdA-",
        "outputId": "7187d03a-ccb8-4dc0-ada5-3c483784be95"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- movie_id: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Número atual de partições:\", df.rdd.getNumPartitions())\n"
      ],
      "metadata": {
        "id": "rMXZymMAzHJ1",
        "outputId": "b26156ad-fc11-49a2-b961-35b7953c9d83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número atual de partições: 6\n",
            "Configurações do Spark: [('spark.app.name', 'Michel_DF'), ('spark.app.submitTime', '1731151492639'), ('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'), ('spark.driver.port', '40435'), ('spark.executor.id', 'driver'), ('spark.sql.warehouse.dir', 'file:/content/spark-warehouse'), ('spark.app.startTime', '1731151493303'), ('spark.driver.host', 'd9551e04703e'), ('spark.rdd.compress', 'True'), ('spark.app.id', 'local-1731151495676'), ('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.submit.pyFiles', ''), ('spark.submit.deployMode', 'client'), ('spark.ui.showConsoleProgress', 'true')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupar os dados por movieID para contar quantas avaliações cada filme teve"
      ],
      "metadata": {
        "id": "X6-lwrICyEpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df.groupBy('movie_id').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb0gB-InrdDO",
        "outputId": "05c55fd1-d054-40c2-8a73-0928664e8ab0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|movie_id|count|\n",
            "+--------+-----+\n",
            "|    1088|11935|\n",
            "|    1580|40308|\n",
            "|    3175|14659|\n",
            "|   44022| 4833|\n",
            "|  175197|  610|\n",
            "|    1645|13496|\n",
            "|     471|10631|\n",
            "|    3794|  763|\n",
            "|    8638| 4832|\n",
            "|   33722|  181|\n",
            "|    2142| 2179|\n",
            "|    2366| 6358|\n",
            "|    6658|  740|\n",
            "|    1959| 4763|\n",
            "|    6620| 3865|\n",
            "|   54190| 2351|\n",
            "|    3918| 1371|\n",
            "|   68135| 2676|\n",
            "|    1342| 3546|\n",
            "|    1591| 5351|\n",
            "+--------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "CPU times: user 196 ms, sys: 22.8 ms, total: 219 ms\n",
            "Wall time: 36.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy('movie_id').count().explain()\n"
      ],
      "metadata": {
        "id": "zpQ-d4-Z0X09",
        "outputId": "70fec0d7-460c-4019-94c9-f5bdaeb9cb91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[movie_id#52], functions=[count(1)])\n",
            "   +- Exchange hashpartitioning(movie_id#52, 200), ENSURE_REQUIREMENTS, [plan_id=242]\n",
            "      +- HashAggregate(keys=[movie_id#52], functions=[partial_count(1)])\n",
            "         +- InMemoryTableScan [movie_id#52]\n",
            "               +- InMemoryRelation [user_id#51, movie_id#52, rating#53, timestamp#54], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                     +- FileScan csv [user_id#51,movie_id#52,rating#53,timestamp#54] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/ml-25m/ratings.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<user_id:int,movie_id:int,rating:double,timestamp:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"tabela_filmes\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqmgdWPFrdFt",
        "outputId": "09a1f2c7-9d9f-4072-ee46-209c9898fdf0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------+----------+\n",
            "|user_id|movie_id|rating| timestamp|\n",
            "+-------+--------+------+----------+\n",
            "|      1|     296|   5.0|1147880044|\n",
            "|      1|     306|   3.5|1147868817|\n",
            "|      1|     307|   5.0|1147868828|\n",
            "|      1|     665|   5.0|1147878820|\n",
            "|      1|     899|   3.5|1147868510|\n",
            "+-------+--------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = spark.sql(\"SELECT * FROM tabela_filmes LIMIT 5\")\n",
        "query.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-1gTYA8rdIF",
        "outputId": "9d743391-0991-4b74-9bd5-301c18562e74"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------+----------+\n",
            "|user_id|movie_id|rating| timestamp|\n",
            "+-------+--------+------+----------+\n",
            "|      1|     296|   5.0|1147880044|\n",
            "|      1|     306|   3.5|1147868817|\n",
            "|      1|     307|   5.0|1147868828|\n",
            "|      1|     665|   5.0|1147878820|\n",
            "|      1|     899|   3.5|1147868510|\n",
            "+-------+--------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query.explain(mode=\"formatted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni7FROaZrdLh",
        "outputId": "db4f9b91-6aef-40a1-e497-e49ae4ad73a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan (5)\n",
            "+- CollectLimit (4)\n",
            "   +- InMemoryTableScan (1)\n",
            "         +- InMemoryRelation (2)\n",
            "               +- Scan csv  (3)\n",
            "\n",
            "\n",
            "(1) InMemoryTableScan\n",
            "Output [4]: [user_id#51, movie_id#52, rating#53, timestamp#54]\n",
            "Arguments: [user_id#51, movie_id#52, rating#53, timestamp#54]\n",
            "\n",
            "(2) InMemoryRelation\n",
            "Arguments: [user_id#51, movie_id#52, rating#53, timestamp#54], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@11a36655,StorageLevel(disk, memory, deserialized, 1 replicas),FileScan csv [user_id#51,movie_id#52,rating#53,timestamp#54] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/ml-25m/ratings.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<user_id:int,movie_id:int,rating:double,timestamp:string>\n",
            ",None)\n",
            "\n",
            "(3) Scan csv \n",
            "Output [4]: [user_id#51, movie_id#52, rating#53, timestamp#54]\n",
            "Batched: false\n",
            "Location: InMemoryFileIndex [file:/content/ml-25m/ratings.csv]\n",
            "ReadSchema: struct<user_id:int,movie_id:int,rating:double,timestamp:string>\n",
            "\n",
            "(4) CollectLimit\n",
            "Input [4]: [user_id#51, movie_id#52, rating#53, timestamp#54]\n",
            "Arguments: 5\n",
            "\n",
            "(5) AdaptiveSparkPlan\n",
            "Output [4]: [user_id#51, movie_id#52, rating#53, timestamp#54]\n",
            "Arguments: isFinalPlan=false\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = spark.sql(\"SELECT movie_id, COUNT(*) AS count FROM tabela_filmes WHERE rating = 5 GROUP BY movie_id ORDER BY 2 DESC\")\n",
        "query.show()"
      ],
      "metadata": {
        "id": "A9VjsMfR1DjL",
        "outputId": "ce5df4b0-f3ee-428a-d3db-189e667d0b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|movie_id|count|\n",
            "+--------+-----+\n",
            "|     318|39553|\n",
            "|     296|32169|\n",
            "|     356|25918|\n",
            "|     260|25804|\n",
            "|    2571|25482|\n",
            "|     527|24853|\n",
            "|     593|24801|\n",
            "|     858|24418|\n",
            "|      50|21585|\n",
            "|    2959|21486|\n",
            "|    1196|20893|\n",
            "|     110|18785|\n",
            "|    4993|18611|\n",
            "|    1198|17725|\n",
            "|    2858|17057|\n",
            "|    7153|16779|\n",
            "|     608|16057|\n",
            "|    5952|15858|\n",
            "|    1210|15665|\n",
            "|     589|14774|\n",
            "+--------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nhjxrWty1Dmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-hbWYUA1DqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GJAHGqtb1Dt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W64zQt0v1Dww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hjp87HfO1DzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Akx6slvN1D1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rDjYwKSw1D4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T19:53:59.440442Z",
          "start_time": "2021-05-20T19:53:59.015732Z"
        },
        "id": "w5CHY8GkJiXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16d8a30-fff7-4ca5-ec76-a516f343a1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------+\n",
            "|PRODUTO;QUANTIDADE;PRECO UNIT. (R$)|\n",
            "+-----------------------------------+\n",
            "|                Achocolatado;2;5.89|\n",
            "|                      Acucar;3;2.03|\n",
            "|                       Agua;10;1.89|\n",
            "|                      Alface;1;2.99|\n",
            "|                      Arroz;4;14.87|\n",
            "+-----------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.options(header=True).csv('supermercado.csv')\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T19:54:11.793463Z",
          "start_time": "2021-05-20T19:54:11.535305Z"
        },
        "id": "2OWdwstWJiXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b061898e-9676-43ec-af92-7078800f5039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+----------------+\n",
            "|     PRODUTO|QUANTIDADE|PRECO UNIT. (R$)|\n",
            "+------------+----------+----------------+\n",
            "|Achocolatado|         2|            5.89|\n",
            "|      Acucar|         3|            2.03|\n",
            "|        Agua|        10|            1.89|\n",
            "|      Alface|         1|            2.99|\n",
            "|       Arroz|         4|           14.87|\n",
            "+------------+----------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.options(header=True, delimiter=\";\").csv('supermercado.csv')\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T19:55:02.741016Z",
          "start_time": "2021-05-20T19:55:02.735348Z"
        },
        "id": "OiGu4Fd4JiXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb95e86c-8ff3-43ae-818a-e613d847fa4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+----------------+\n",
            "|     PRODUTO|QUANTIDADE|PRECO UNIT. (R$)|\n",
            "+------------+----------+----------------+\n",
            "|Achocolatado|       2.0|            5.89|\n",
            "|      Acucar|       3.0|            2.03|\n",
            "|        Agua|      10.0|            1.89|\n",
            "|      Alface|       1.0|            2.99|\n",
            "|       Arroz|       4.0|           14.87|\n",
            "+------------+----------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.options(header=True, delimiter=\";\", inferSchema=True).csv('supermercado.csv')\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T19:55:09.291075Z",
          "start_time": "2021-05-20T19:55:09.285145Z"
        },
        "id": "q6qBnXfPJiXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4683e7dd-d685-44fb-9792-9f8dab102e5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('PRODUTO', StringType(), True), StructField('QUANTIDADE', DoubleType(), True), StructField('PRECO UNIT. (R$)', DoubleType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "df.schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T19:55:18.054126Z",
          "start_time": "2021-05-20T19:55:18.045350Z"
        },
        "id": "1GCzWjaCJiXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a061fa-987c-474f-95eb-c39012e809b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+--------+\n",
            "|     produto|quantidade|preco_UN|\n",
            "+------------+----------+--------+\n",
            "|Achocolatado|       2.0|    5.89|\n",
            "|      Acucar|       3.0|    2.03|\n",
            "|        Agua|      10.0|    1.89|\n",
            "|      Alface|       1.0|    2.99|\n",
            "|       Arroz|       4.0|   14.87|\n",
            "+------------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.options(header=True, delimiter=\";\", inferSchema=True).csv('supermercado.csv').toDF(\"produto\",\"quantidade\",\"preco_UN\")\n",
        "df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as sf\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType, DoubleType, TimestampType, IntegerType, StructType, StructField, BooleanType"
      ],
      "metadata": {
        "id": "ACcsZPJdTmrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T19:58:59.859416Z",
          "start_time": "2021-05-20T19:58:59.855595Z"
        },
        "id": "kSCZZcFeJiXc"
      },
      "outputs": [],
      "source": [
        "spark_udf = udf(lambda x: x>5,returnType=BooleanType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:25:29.759760Z",
          "start_time": "2021-05-20T20:25:29.755337Z"
        },
        "id": "kWwdyX1MJiXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68c9409e-04e0-4657-99cc-0737bca9717d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+--------+-------+\n",
            "|            produto|quantidade|preco_UN|maior_5|\n",
            "+-------------------+----------+--------+-------+\n",
            "|       Achocolatado|       2.0|    5.89|  false|\n",
            "|             Acucar|       3.0|    2.03|  false|\n",
            "|               Agua|      10.0|    1.89|   true|\n",
            "|             Alface|       1.0|    2.99|  false|\n",
            "|              Arroz|       4.0|   14.87|  false|\n",
            "|               Atum|       3.0|    7.45|  false|\n",
            "|             Azeite|       2.0|    17.8|  false|\n",
            "|           Azeitona|       2.0|    8.04|  false|\n",
            "|             Batata|       2.8|    4.99|  false|\n",
            "|       Batata palha|       5.0|    5.99|  false|\n",
            "|               Cafe|       3.0|     9.7|  false|\n",
            "|             Cebola|      0.76|    3.45|  false|\n",
            "|            Cenoura|      1.98|    3.99|  false|\n",
            "|                Cha|       2.0|    3.67|  false|\n",
            "|          Chocolate|       1.0|     9.9|  false|\n",
            "|        Coco ralado|       2.0|    3.78|  false|\n",
            "|     Creme de Leite|       5.0|    2.46|  false|\n",
            "|Farinha de mandioca|       1.0|     4.0|  false|\n",
            "|   Farinha de milho|       1.0|    4.05|  false|\n",
            "|   Farinha de trigo|       3.0|    3.78|  false|\n",
            "+-------------------+----------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"maior_5\",spark_udf(sf.col(\"quantidade\"))).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:25:30.061298Z",
          "start_time": "2021-05-20T20:25:30.055250Z"
        },
        "id": "DUPrrtJbJiXg"
      },
      "outputs": [],
      "source": [
        "is_integer_udf = udf(lambda x: x.is_integer(), returnType=BooleanType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:25:30.480166Z",
          "start_time": "2021-05-20T20:25:30.475509Z"
        },
        "id": "eieSrsVkJiXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55c04ba-55d0-4502-a610-31d9ccf7fd47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+--------+-------+\n",
            "|            produto|quantidade|preco_UN|inteiro|\n",
            "+-------------------+----------+--------+-------+\n",
            "|       Achocolatado|       2.0|    5.89|  false|\n",
            "|             Acucar|       3.0|    2.03|  false|\n",
            "|               Agua|      10.0|    1.89|  false|\n",
            "|             Alface|       1.0|    2.99|  false|\n",
            "|              Arroz|       4.0|   14.87|  false|\n",
            "|               Atum|       3.0|    7.45|  false|\n",
            "|             Azeite|       2.0|    17.8|  false|\n",
            "|           Azeitona|       2.0|    8.04|  false|\n",
            "|             Batata|       2.8|    4.99|  false|\n",
            "|       Batata palha|       5.0|    5.99|  false|\n",
            "|               Cafe|       3.0|     9.7|  false|\n",
            "|             Cebola|      0.76|    3.45|  false|\n",
            "|            Cenoura|      1.98|    3.99|  false|\n",
            "|                Cha|       2.0|    3.67|  false|\n",
            "|          Chocolate|       1.0|     9.9|  false|\n",
            "|        Coco ralado|       2.0|    3.78|  false|\n",
            "|     Creme de Leite|       5.0|    2.46|  false|\n",
            "|Farinha de mandioca|       1.0|     4.0|   true|\n",
            "|   Farinha de milho|       1.0|    4.05|  false|\n",
            "|   Farinha de trigo|       3.0|    3.78|  false|\n",
            "+-------------------+----------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"inteiro\",is_integer_udf(sf.col(\"preco_UN\"))).show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"inteiro\",is_integer_udf(sf.col(\"quantidade\"))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wElEaTnmWu-b",
        "outputId": "3dc297e8-9907-4380-dd2f-b622df38e651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+--------+-------+\n",
            "|            produto|quantidade|preco_UN|inteiro|\n",
            "+-------------------+----------+--------+-------+\n",
            "|       Achocolatado|       2.0|    5.89|   true|\n",
            "|             Acucar|       3.0|    2.03|   true|\n",
            "|               Agua|      10.0|    1.89|   true|\n",
            "|             Alface|       1.0|    2.99|   true|\n",
            "|              Arroz|       4.0|   14.87|   true|\n",
            "|               Atum|       3.0|    7.45|   true|\n",
            "|             Azeite|       2.0|    17.8|   true|\n",
            "|           Azeitona|       2.0|    8.04|   true|\n",
            "|             Batata|       2.8|    4.99|  false|\n",
            "|       Batata palha|       5.0|    5.99|   true|\n",
            "|               Cafe|       3.0|     9.7|   true|\n",
            "|             Cebola|      0.76|    3.45|  false|\n",
            "|            Cenoura|      1.98|    3.99|  false|\n",
            "|                Cha|       2.0|    3.67|   true|\n",
            "|          Chocolate|       1.0|     9.9|   true|\n",
            "|        Coco ralado|       2.0|    3.78|   true|\n",
            "|     Creme de Leite|       5.0|    2.46|   true|\n",
            "|Farinha de mandioca|       1.0|     4.0|   true|\n",
            "|   Farinha de milho|       1.0|    4.05|   true|\n",
            "|   Farinha de trigo|       3.0|    3.78|   true|\n",
            "+-------------------+----------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.withColumn(\"qtde_arrumada\",sf.when(is_integer_udf(sf.col(\"quantidade\")),sf.col(\"quantidade\")).otherwise(1))\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wKy6DZzW-4z",
        "outputId": "6fdb06c0-b990-4377-c2f8-2e89b6687711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+--------+-------------+\n",
            "|            produto|quantidade|preco_UN|qtde_arrumada|\n",
            "+-------------------+----------+--------+-------------+\n",
            "|       Achocolatado|       2.0|    5.89|          2.0|\n",
            "|             Acucar|       3.0|    2.03|          3.0|\n",
            "|               Agua|      10.0|    1.89|         10.0|\n",
            "|             Alface|       1.0|    2.99|          1.0|\n",
            "|              Arroz|       4.0|   14.87|          4.0|\n",
            "|               Atum|       3.0|    7.45|          3.0|\n",
            "|             Azeite|       2.0|    17.8|          2.0|\n",
            "|           Azeitona|       2.0|    8.04|          2.0|\n",
            "|             Batata|       2.8|    4.99|          1.0|\n",
            "|       Batata palha|       5.0|    5.99|          5.0|\n",
            "|               Cafe|       3.0|     9.7|          3.0|\n",
            "|             Cebola|      0.76|    3.45|          1.0|\n",
            "|            Cenoura|      1.98|    3.99|          1.0|\n",
            "|                Cha|       2.0|    3.67|          2.0|\n",
            "|          Chocolate|       1.0|     9.9|          1.0|\n",
            "|        Coco ralado|       2.0|    3.78|          2.0|\n",
            "|     Creme de Leite|       5.0|    2.46|          5.0|\n",
            "|Farinha de mandioca|       1.0|     4.0|          1.0|\n",
            "|   Farinha de milho|       1.0|    4.05|          1.0|\n",
            "|   Farinha de trigo|       3.0|    3.78|          3.0|\n",
            "+-------------------+----------+--------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.agg({\"qtde_arrumada\":\"sum\"}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6biUSAoXku2",
        "outputId": "120415e8-97a6-4a75-eec4-3b7795317185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|sum(qtde_arrumada)|\n",
            "+------------------+\n",
            "|             122.0|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: quero gerar uma coluna contendo o valor total da compra (quantidade X preço)\n",
        "\n",
        "df3 = df2.withColumn(\"valor_total\", sf.col(\"preco_UN\") * sf.col(\"qtde_arrumada\"))\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufJKjdf7YmqQ",
        "outputId": "585f0c5f-0be5-47a4-8c37-bcdd3dcd5dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+--------+-------------+------------------+\n",
            "|            produto|quantidade|preco_UN|qtde_arrumada|       valor_total|\n",
            "+-------------------+----------+--------+-------------+------------------+\n",
            "|       Achocolatado|       2.0|    5.89|          2.0|             11.78|\n",
            "|             Acucar|       3.0|    2.03|          3.0|              6.09|\n",
            "|               Agua|      10.0|    1.89|         10.0|              18.9|\n",
            "|             Alface|       1.0|    2.99|          1.0|              2.99|\n",
            "|              Arroz|       4.0|   14.87|          4.0|             59.48|\n",
            "|               Atum|       3.0|    7.45|          3.0|             22.35|\n",
            "|             Azeite|       2.0|    17.8|          2.0|              35.6|\n",
            "|           Azeitona|       2.0|    8.04|          2.0|             16.08|\n",
            "|             Batata|       2.8|    4.99|          1.0|              4.99|\n",
            "|       Batata palha|       5.0|    5.99|          5.0|29.950000000000003|\n",
            "|               Cafe|       3.0|     9.7|          3.0|29.099999999999998|\n",
            "|             Cebola|      0.76|    3.45|          1.0|              3.45|\n",
            "|            Cenoura|      1.98|    3.99|          1.0|              3.99|\n",
            "|                Cha|       2.0|    3.67|          2.0|              7.34|\n",
            "|          Chocolate|       1.0|     9.9|          1.0|               9.9|\n",
            "|        Coco ralado|       2.0|    3.78|          2.0|              7.56|\n",
            "|     Creme de Leite|       5.0|    2.46|          5.0|              12.3|\n",
            "|Farinha de mandioca|       1.0|     4.0|          1.0|               4.0|\n",
            "|   Farinha de milho|       1.0|    4.05|          1.0|              4.05|\n",
            "|   Farinha de trigo|       3.0|    3.78|          3.0|             11.34|\n",
            "+-------------------+----------+--------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.agg({\"valor_total\":\"sum\"}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV2lOh0LY21b",
        "outputId": "c57065cf-20cb-42bd-e292-d4f20b8d81f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "| sum(valor_total)|\n",
            "+-----------------+\n",
            "|798.8499999999998|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.sort(sf.col(\"valor_total\").desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOsQfdeFZs2F",
        "outputId": "16a64c4a-da05-4356-e6fd-f0b6fe8baa5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+--------+-------------+------------------+\n",
            "|       produto|quantidade|preco_UN|qtde_arrumada|       valor_total|\n",
            "+--------------+----------+--------+-------------+------------------+\n",
            "|         Vinho|       2.0|    37.0|          2.0|              74.0|\n",
            "|         Arroz|       4.0|   14.87|          4.0|             59.48|\n",
            "|      Presunto|      0.35|    50.0|          1.0|              50.0|\n",
            "|          Suco|      10.0|    4.97|         10.0|49.699999999999996|\n",
            "|        Queijo|       0.4|    45.0|          1.0|              45.0|\n",
            "|     Mortadela|       0.3|    40.0|          1.0|              40.0|\n",
            "|        Geleia|       4.0|     8.9|          4.0|              35.6|\n",
            "|        Azeite|       2.0|    17.8|          2.0|              35.6|\n",
            "|  Refrigerante|       5.0|     6.0|          5.0|              30.0|\n",
            "|  Batata palha|       5.0|    5.99|          5.0|29.950000000000003|\n",
            "|          Cafe|       3.0|     9.7|          3.0|29.099999999999998|\n",
            "|          Atum|       3.0|    7.45|          3.0|             22.35|\n",
            "|      Manteiga|       2.0|     9.9|          2.0|              19.8|\n",
            "|      Sardinha|       4.0|    4.89|          4.0|             19.56|\n",
            "|          Agua|      10.0|    1.89|         10.0|              18.9|\n",
            "|      Azeitona|       2.0|    8.04|          2.0|             16.08|\n",
            "|  Molho branco|       5.0|    2.88|          5.0|14.399999999999999|\n",
            "|          Maca|      2.02|   12.99|          1.0|             12.99|\n",
            "|Creme de Leite|       5.0|    2.46|          5.0|              12.3|\n",
            "|          Oleo|       2.0|     6.0|          2.0|              12.0|\n",
            "+--------------+----------+--------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:25:31.466072Z",
          "start_time": "2021-05-20T20:25:31.435433Z"
        },
        "id": "eqisgLHpJiXi"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('../10_dados/movie_lens/ratings.csv', header=True, schema = schema )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:25:31.921871Z",
          "start_time": "2021-05-20T20:25:31.916617Z"
        },
        "id": "2LK3Ey6cJiXj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:25:34.493677Z",
          "start_time": "2021-05-20T20:25:34.125235Z"
        },
        "id": "WO6bi5s2JiXl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:27:11.017949Z",
          "start_time": "2021-05-20T20:27:10.725449Z"
        },
        "id": "zuIywrgTJiXl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:27:57.440840Z",
          "start_time": "2021-05-20T20:27:57.028609Z"
        },
        "id": "DbpP-RXBJiXm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:29:20.465692Z",
          "start_time": "2021-05-20T20:29:20.445417Z"
        },
        "id": "2FmSGviOJiXn"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import lit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:29:48.461981Z",
          "start_time": "2021-05-20T20:29:48.443655Z"
        },
        "id": "ivMD_6DVJiXo"
      },
      "outputs": [],
      "source": [
        "# Criar a sessao do Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "            .builder \\\n",
        "            .master(\"local[*]\") \\\n",
        "            .appName(\"Michel_DF\") \\\n",
        "            .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:29:49.315111Z",
          "start_time": "2021-05-20T20:29:49.035698Z"
        },
        "id": "4ot9EkXYJiXp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:31:25.436192Z",
          "start_time": "2021-05-20T20:31:25.385370Z"
        },
        "id": "QA0UK5QxJiXq"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('/content/ml-25m/ratings.csv', header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:31:30.884229Z",
          "start_time": "2021-05-20T20:31:30.475631Z"
        },
        "id": "18nvZwSdJiXr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:32:08.470291Z",
          "start_time": "2021-05-20T20:32:08.455277Z"
        },
        "id": "qfXOI2eNJiXt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:32:11.036945Z",
          "start_time": "2021-05-20T20:32:10.878419Z"
        },
        "id": "dSV_Yb_XJiXv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:33:18.929177Z",
          "start_time": "2021-05-20T20:32:49.955959Z"
        },
        "id": "3FhqV3JwJiXw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:33:56.640954Z",
          "start_time": "2021-05-20T20:33:49.385757Z"
        },
        "id": "s8fye18SJiXx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:35:09.794484Z",
          "start_time": "2021-05-20T20:35:09.505251Z"
        },
        "id": "TAAuCn-TJiXy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:36:18.533696Z",
          "start_time": "2021-05-20T20:36:18.515114Z"
        },
        "id": "3LsLzyG2JiXy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:37:56.319942Z",
          "start_time": "2021-05-20T20:37:56.295157Z"
        },
        "id": "Lf_9Vq1ZJiXz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:38:39.410096Z",
          "start_time": "2021-05-20T20:38:39.098228Z"
        },
        "id": "YRFPBb-eJiX0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:42:00.169356Z",
          "start_time": "2021-05-20T20:42:00.055291Z"
        },
        "id": "x2dvGTjEJiX1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:42:01.808240Z",
          "start_time": "2021-05-20T20:42:01.700936Z"
        },
        "id": "BEwaqTk3JiX2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:42:28.042780Z",
          "start_time": "2021-05-20T20:42:04.635241Z"
        },
        "id": "zFOl4qPLJiX3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:43:42.209948Z",
          "start_time": "2021-05-20T20:43:42.205681Z"
        },
        "id": "g9Jv8xGLJiX5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:45:54.751926Z",
          "start_time": "2021-05-20T20:45:29.688390Z"
        },
        "id": "wCRYAF6uJiX6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:46:00.514313Z",
          "start_time": "2021-05-20T20:46:00.395710Z"
        },
        "id": "Ux-Ow067JiX7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:46:51.203492Z",
          "start_time": "2021-05-20T20:46:51.179137Z"
        },
        "id": "MdQsXQKgJiX8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:49:52.961714Z",
          "start_time": "2021-05-20T20:49:28.855213Z"
        },
        "id": "jpMYaSnGJiX8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-20T20:48:45.231492Z",
          "start_time": "2021-05-20T20:48:21.805178Z"
        },
        "id": "uD0UYDJSJiX9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g2ffclDJiYA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}